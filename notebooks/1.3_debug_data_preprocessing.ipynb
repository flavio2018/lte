{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "05d92980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data import generate_sample\n",
    "from data.generator import get_vocab_size, get_token2pos\n",
    "from utils.rnn_utils import make_tensor\n",
    "from model.test import target_tensors_to_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e908a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN = 1\n",
    "NES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5e21a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_sample(LEN, NES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2bc179bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print((8+0))'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7c1d6b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9376ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = make_tensor(x, get_token2pos(), get_vocab_size())\n",
    "y_t = make_tensor(y, get_token2pos(), get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "315f4c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print((8+0))'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensors_to_str(x_t.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a769b7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'------------------------------------------------'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensors_to_str(y_t.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7192b1d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f1993a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.generator import generate_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8814e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_size():\n",
    "    return len(get_vocab_chars()) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3410ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token2pos():\n",
    "    token2pos = {t: p for p, t in enumerate(get_vocab_chars())}\n",
    "    token2pos['\\n'] = len(token2pos)\n",
    "    token2pos['#'] = len(token2pos)  # padding\n",
    "    return token2pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "27d38703",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN = 2\n",
    "BS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "70d976d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, X_lens, Y_lens = generate_batch(LEN, NES, BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "76489e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 14, 14, 14, 14, 13, 14, 14, 13, 14, 14, 13, 13, 14, 14, 14]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eba97b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 14, 48])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ed0af7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print((6+93))#\n",
      "print((29+38))\n",
      "print((69+91))\n",
      "print((77+58))\n",
      "print((67+69))\n",
      "print((86+3))#\n",
      "print((35+73))\n",
      "print((90+32))\n",
      "print((34+3))#\n",
      "print((73+26))\n",
      "print((40+48))\n",
      "print((2+39))#\n",
      "print((50+5))#\n",
      "print((84+34))\n",
      "print((35+16))\n",
      "print((39+38))\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    print(target_tensors_to_str(X[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4afa219f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n",
      "69=\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Y)):\n",
    "    print(target_tensors_to_str(Y[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lte",
   "language": "python",
   "name": "lte"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
